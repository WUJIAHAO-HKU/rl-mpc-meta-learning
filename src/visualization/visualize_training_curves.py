#!/usr/bin/env python3
"""
è®­ç»ƒæ›²çº¿å¯è§†åŒ–
å±•ç¤ºRLè®­ç»ƒè¿‡ç¨‹ä¸­çš„å¥–åŠ±ã€è¯¯å·®å’Œä»·å€¼å‡½æ•°å˜åŒ–
"""

import numpy as np
import matplotlib.pyplot as plt
import argparse
import os


def plot_training_curves(eval_npz_path, save_path='training_curves.png'):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    
    Args:
        eval_npz_path: evaluations.npzæ–‡ä»¶è·¯å¾„
        save_path: ä¿å­˜è·¯å¾„
    """
    # åŠ è½½è¯„ä¼°æ•°æ®
    data = np.load(eval_npz_path)
    timesteps = data['timesteps']
    results = data['results']  # å¹³å‡å¥–åŠ±
    ep_lengths = data['ep_lengths']  # å›žåˆé•¿åº¦
    
    # å¤„ç†å¤šç»´æ•°ç»„ï¼ˆå–å¹³å‡å€¼ï¼‰
    if len(results.shape) > 1:
        results = np.mean(results, axis=1)
    if len(ep_lengths.shape) > 1:
        ep_lengths = np.mean(ep_lengths, axis=1)
    
    print(f"âœ… åŠ è½½è®­ç»ƒæ•°æ®: {eval_npz_path}")
    print(f"   è®­ç»ƒæ­¥æ•°: {timesteps[-1]}")
    print(f"   è¯„ä¼°æ¬¡æ•°: {len(timesteps)}")
    print(f"   æœ€ç»ˆå¥–åŠ±: {results[-1]:.2f}")
    print(f"   å¥–åŠ±æ”¹å–„: {results[-1] - results[0]:.2f}")
    
    # åˆ›å»ºå›¾è¡¨
    fig = plt.figure(figsize=(15, 10))
    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)
    
    # 1. å¥–åŠ±æ›²çº¿ï¼ˆåŽŸå§‹ + å¹³æ»‘ï¼‰
    ax1 = fig.add_subplot(gs[0, :])
    ax1.plot(timesteps, results, alpha=0.3, color='blue', label='Raw Reward')
    
    # å¹³æ»‘å¤„ç†ï¼ˆç§»åŠ¨å¹³å‡ï¼‰
    window = min(5, len(results))
    if window > 1:
        smoothed = np.convolve(results, np.ones(window)/window, mode='valid')
        smoothed_timesteps = timesteps[:len(smoothed)]
        ax1.plot(smoothed_timesteps, smoothed, color='blue', linewidth=2, label='Smoothed Reward')
    
    ax1.set_xlabel('Training Steps', fontsize=12)
    ax1.set_ylabel('Mean Reward', fontsize=12)
    ax1.set_title('RL Training Progress: Reward Evolution', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # æ ‡æ³¨èµ·å§‹å’Œæœ€ç»ˆå¥–åŠ±
    ax1.annotate(f'Start: {results[0]:.1f}', 
                xy=(timesteps[0], results[0]),
                xytext=(timesteps[0], results[0] + (results[-1] - results[0]) * 0.1),
                arrowprops=dict(arrowstyle='->', color='red'),
                fontsize=10, color='red')
    
    ax1.annotate(f'Final: {results[-1]:.1f}', 
                xy=(timesteps[-1], results[-1]),
                xytext=(timesteps[-1] * 0.85, results[-1]),
                arrowprops=dict(arrowstyle='->', color='green'),
                fontsize=10, color='green')
    
    # 2. å›žåˆé•¿åº¦å˜åŒ–
    ax2 = fig.add_subplot(gs[1, 0])
    ax2.plot(timesteps, ep_lengths, color='orange', linewidth=2)
    ax2.set_xlabel('Training Steps', fontsize=12)
    ax2.set_ylabel('Episode Length', fontsize=12)
    ax2.set_title('Episode Length During Training', fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # 3. å¥–åŠ±æ”¹å–„çŽ‡ï¼ˆç›¸å¯¹äºŽåˆå§‹å€¼ï¼‰
    ax3 = fig.add_subplot(gs[1, 1])
    improvement = (results - results[0]) / abs(results[0]) * 100
    ax3.plot(timesteps, improvement, color='green', linewidth=2)
    ax3.axhline(y=0, color='black', linestyle='--', linewidth=1)
    ax3.set_xlabel('Training Steps', fontsize=12)
    ax3.set_ylabel('Improvement (%)', fontsize=12)
    ax3.set_title('Reward Improvement Relative to Start', fontsize=12, fontweight='bold')
    ax3.grid(True, alpha=0.3)
    ax3.fill_between(timesteps, 0, improvement, where=(improvement > 0), 
                     alpha=0.3, color='green', label='Improvement')
    ax3.fill_between(timesteps, 0, improvement, where=(improvement < 0), 
                     alpha=0.3, color='red', label='Degradation')
    ax3.legend()
    
    # 4. å¥–åŠ±åˆ†å¸ƒï¼ˆç›´æ–¹å›¾ï¼‰
    ax4 = fig.add_subplot(gs[2, 0])
    ax4.hist(results, bins=30, alpha=0.7, color='purple', edgecolor='black')
    ax4.axvline(np.mean(results), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(results):.2f}')
    ax4.axvline(np.median(results), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(results):.2f}')
    ax4.set_xlabel('Mean Reward', fontsize=12)
    ax4.set_ylabel('Frequency', fontsize=12)
    ax4.set_title('Reward Distribution', fontsize=12, fontweight='bold')
    ax4.legend()
    ax4.grid(True, alpha=0.3, axis='y')
    
    # 5. è®­ç»ƒé˜¶æ®µåˆ†æžï¼ˆå‰25%ã€ä¸­50%ã€åŽ25%ï¼‰
    ax5 = fig.add_subplot(gs[2, 1])
    n = len(results)
    early = results[:n//4]
    middle = results[n//4:3*n//4]
    late = results[3*n//4:]
    
    stages = ['Early\n(0-25%)', 'Middle\n(25-75%)', 'Late\n(75-100%)']
    means = [np.mean(early), np.mean(middle), np.mean(late)]
    stds = [np.std(early), np.std(middle), np.std(late)]
    
    x_pos = np.arange(len(stages))
    bars = ax5.bar(x_pos, means, yerr=stds, alpha=0.7, capsize=5,
                   color=['skyblue', 'lightgreen', 'lightcoral'],
                   edgecolor='black', linewidth=1.5)
    
    ax5.set_xlabel('Training Stage', fontsize=12)
    ax5.set_ylabel('Mean Reward', fontsize=12)
    ax5.set_title('Performance by Training Stage', fontsize=12, fontweight='bold')
    ax5.set_xticks(x_pos)
    ax5.set_xticklabels(stages)
    ax5.grid(True, alpha=0.3, axis='y')
    
    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨æ•°å€¼
    for i, (bar, mean) in enumerate(zip(bars, means)):
        height = bar.get_height()
        ax5.text(bar.get_x() + bar.get_width()/2., height,
                f'{mean:.1f}',
                ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # ä¿å­˜å›¾è¡¨
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nðŸ“Š è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nðŸ“ˆ è®­ç»ƒç»Ÿè®¡:")
    print(f"   èµ·å§‹å¥–åŠ±:   {results[0]:.2f}")
    print(f"   æœ€ç»ˆå¥–åŠ±:   {results[-1]:.2f}")
    print(f"   å¹³å‡å¥–åŠ±:   {np.mean(results):.2f}")
    print(f"   ä¸­ä½å¥–åŠ±:   {np.median(results):.2f}")
    print(f"   æ ‡å‡†å·®:     {np.std(results):.2f}")
    print(f"   æœ€å¤§å¥–åŠ±:   {np.max(results):.2f}")
    print(f"   æœ€å°å¥–åŠ±:   {np.min(results):.2f}")
    print(f"   æ€»æ”¹å–„:     {results[-1] - results[0]:.2f} ({(results[-1] - results[0]) / abs(results[0]) * 100:+.2f}%)")
    
    return {
        'timesteps': timesteps,
        'rewards': results,
        'ep_lengths': ep_lengths,
        'initial_reward': results[0],
        'final_reward': results[-1],
        'mean_reward': np.mean(results),
        'improvement': results[-1] - results[0]
    }


def compare_multiple_runs(eval_paths, labels, save_path='training_comparison.png'):
    """
    å¯¹æ¯”å¤šæ¬¡è®­ç»ƒè¿è¡Œ
    
    Args:
        eval_paths: evaluations.npzæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        labels: æ ‡ç­¾åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
    """
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    colors = ['blue', 'orange', 'green', 'red', 'purple']
    
    for i, (path, label) in enumerate(zip(eval_paths, labels)):
        if not os.path.exists(path):
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            continue
        
        data = np.load(path)
        timesteps = data['timesteps']
        results = data['results']
        
        # å¥–åŠ±æ›²çº¿
        ax1.plot(timesteps, results, color=colors[i % len(colors)], 
                linewidth=2, label=label, alpha=0.8)
        
        # ç´¯ç§¯æ”¹å–„
        improvement = (results - results[0]) / abs(results[0]) * 100
        ax2.plot(timesteps, improvement, color=colors[i % len(colors)],
                linewidth=2, label=label, alpha=0.8)
    
    ax1.set_xlabel('Training Steps')
    ax1.set_ylabel('Mean Reward')
    ax1.set_title('Training Curves Comparison')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    ax2.set_xlabel('Training Steps')
    ax2.set_ylabel('Improvement (%)')
    ax2.set_title('Relative Improvement Comparison')
    ax2.axhline(y=0, color='black', linestyle='--', linewidth=1)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nðŸ“Š å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")


def main():
    parser = argparse.ArgumentParser(description='å¯è§†åŒ–RLè®­ç»ƒæ›²çº¿')
    parser.add_argument('--eval_path', 
                        default='logs/meta_rl_panda/evaluations.npz',
                        help='evaluations.npzæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', 
                        default='training_curves.png',
                        help='è¾“å‡ºå›¾ç‰‡è·¯å¾„')
    args = parser.parse_args()
    
    print("="*80)
    print("RLè®­ç»ƒæ›²çº¿å¯è§†åŒ–")
    print("="*80)
    print(f"è¯„ä¼°æ–‡ä»¶: {args.eval_path}")
    print()
    
    if not os.path.exists(args.eval_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {args.eval_path}")
        print(f"\nðŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬ç”Ÿæˆè¯„ä¼°æ•°æ®")
        return
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    stats = plot_training_curves(args.eval_path, args.output)
    
    print("\n" + "="*80)
    print("âœ… å¯è§†åŒ–å®Œæˆï¼")
    print("="*80)


if __name__ == '__main__':
    main()

