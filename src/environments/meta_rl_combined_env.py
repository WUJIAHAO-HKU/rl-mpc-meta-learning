#!/usr/bin/env python3
"""
å…ƒå­¦ä¹ PID + RLç»“åˆç¯å¢ƒ
ä½¿ç”¨å…ƒå­¦ä¹ é¢„æµ‹çš„PIDä½œä¸ºåˆå§‹å€¼ï¼ŒRLè¿›è¡Œå¾®è°ƒ
"""

import numpy as np
import pybullet as p
import pybullet_data
import torch
import torch.nn as nn
from pathlib import Path
import gymnasium as gym
from gymnasium import spaces


# ============================================================================
# åŠ è½½å…ƒå­¦ä¹ PIDæ¨¡å‹
# ============================================================================
class SimplePIDPredictor(nn.Module):
    """å…ƒå­¦ä¹ PIDé¢„æµ‹å™¨"""
    def __init__(self, input_dim=4, hidden_dim=64, output_dim=3):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim),
            nn.Softplus()
        )
    
    def forward(self, x):
        return self.network(x)


def load_meta_pid_model(model_path):
    """åŠ è½½è®­ç»ƒå¥½çš„å…ƒå­¦ä¹ PIDæ¨¡å‹"""
    checkpoint = torch.load(model_path, map_location='cpu')
    
    model = SimplePIDPredictor(input_dim=4, hidden_dim=64, output_dim=3)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    return model, checkpoint['X_mean'], checkpoint['X_std'], checkpoint['y_mean'], checkpoint['y_std']


def predict_initial_pid(model, robot_features, X_mean, X_std, y_mean, y_std):
    """ä½¿ç”¨å…ƒå­¦ä¹ æ¨¡å‹é¢„æµ‹åˆå§‹PID"""
    # æ ‡å‡†åŒ–
    features_norm = (robot_features - X_mean) / X_std
    
    # é¢„æµ‹
    with torch.no_grad():
        features_t = torch.FloatTensor(features_norm).unsqueeze(0)
        pred_norm = model(features_t).squeeze(0).numpy()
    
    # åæ ‡å‡†åŒ–
    pred_log = pred_norm * y_std + y_mean
    pred = np.exp(pred_log)
    
    return pred  # [kp, ki, kd]


# ============================================================================
# Meta-PID + RL ç¯å¢ƒ
# ============================================================================
class MetaRLCombinedEnv(gym.Env):
    """
    ç»“åˆå…ƒå­¦ä¹ PIDå’ŒRLçš„ç¯å¢ƒ
    
    ç‰¹ç‚¹ï¼š
    1. ä½¿ç”¨å…ƒå­¦ä¹ é¢„æµ‹çš„PIDä½œä¸ºåŸºå‡†
    2. RLå­¦ä¹ å°èŒƒå›´è°ƒæ•´ï¼ˆÂ±20%ï¼‰
    3. å¿«é€Ÿæ”¶æ•›åˆ°æœ€ä¼˜æ€§èƒ½
    """
    
    def __init__(self, robot_urdf='franka_panda/panda.urdf', 
                 meta_model_path=None,
                 gui=False,
                 adjustment_range=0.2):
        """
        Args:
            robot_urdf: æœºå™¨äººURDFè·¯å¾„
            meta_model_path: å…ƒå­¦ä¹ æ¨¡å‹è·¯å¾„
            gui: æ˜¯å¦æ˜¾ç¤ºGUI
            adjustment_range: RLè°ƒæ•´èŒƒå›´ï¼ˆÂ±20%ï¼‰
        """
        super().__init__()
        
        self.robot_urdf = robot_urdf
        self.gui = gui
        self.adjustment_range = adjustment_range
        
        # åŠ è½½å…ƒå­¦ä¹ æ¨¡å‹
        if meta_model_path is None:
            meta_model_path = Path(__file__).parent / 'meta_pid_augmented.pth'
        
        print(f"ğŸ”§ åŠ è½½å…ƒå­¦ä¹ PIDæ¨¡å‹: {meta_model_path.name}")
        self.meta_model, self.X_mean, self.X_std, self.y_mean, self.y_std = load_meta_pid_model(meta_model_path)
        
        # è¿æ¥PyBullet
        if self.gui:
            self.client = p.connect(p.GUI)
        else:
            self.client = p.connect(p.DIRECT)
        
        p.setAdditionalSearchPath(pybullet_data.getDataPath())
        p.setGravity(0, 0, -9.81)
        p.setTimeStep(1./240.)
        
        # åŠ è½½æœºå™¨äºº
        self.robot_id = p.loadURDF(robot_urdf, [0, 0, 0.5], useFixedBase=True)
        
        # è·å–å¯æ§å…³èŠ‚
        self.controllable_joints = []
        for j in range(p.getNumJoints(self.robot_id)):
            info = p.getJointInfo(self.robot_id, j)
            if info[2] != p.JOINT_FIXED:
                self.controllable_joints.append(j)
        
        self.n_dof = len(self.controllable_joints)
        
        # é¢„æµ‹åˆå§‹PIDï¼ˆå…ƒå­¦ä¹ ï¼‰
        robot_features = self._extract_robot_features()
        self.base_pid = predict_initial_pid(
            self.meta_model, robot_features,
            self.X_mean, self.X_std, self.y_mean, self.y_std
        )
        
        print(f"ğŸ¤– æœºå™¨äºº: {robot_urdf}")
        print(f"   è‡ªç”±åº¦: {self.n_dof}")
        print(f"   å…ƒå­¦ä¹ é¢„æµ‹åˆå§‹PID:")
        print(f"      Kp = {self.base_pid[0]:.4f}")
        print(f"      Ki = {self.base_pid[1]:.4f}")
        print(f"      Kd = {self.base_pid[2]:.4f}")
        
        # å®šä¹‰è§‚æµ‹ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´
        # è§‚æµ‹ï¼š[q(n_dof), qd(n_dof), error(n_dof), time_in_episode]
        obs_dim = 3 * self.n_dof + 1
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf, shape=(obs_dim,), dtype=np.float32
        )
        
        # åŠ¨ä½œï¼š[delta_kp_ratio, delta_kd_ratio]ï¼ˆÂ±adjustment_rangeï¼‰
        # å®é™…PID = base_pid * (1 + delta_ratio)
        self.action_space = spaces.Box(
            low=-adjustment_range, high=adjustment_range, 
            shape=(2,), dtype=np.float32
        )
        
        # è½¨è¿¹ç”Ÿæˆå‚æ•°
        self.max_steps = 2000  # çº¦8ç§’
        self.current_step = 0
        
    def _extract_robot_features(self):
        """æå–æœºå™¨äººç‰¹å¾ï¼ˆç”¨äºå…ƒå­¦ä¹ é¢„æµ‹ï¼‰"""
        # ç®€åŒ–ï¼šæ‰‹åŠ¨è®¾ç½®ç‰¹å¾ï¼ˆå®é™…åº”ä»URDFæå–ï¼‰
        if 'panda' in self.robot_urdf:
            features = np.array([9, 14.25, 6.55, 0.0])  # [DOF, mass, reach, payload]
        elif 'laikago' in self.robot_urdf:
            features = np.array([12, 11.45, 3.79, 0.0])
        elif 'kuka' in self.robot_urdf or 'iiwa' in self.robot_urdf:
            features = np.array([7, 17.5, 5.75, 0.0])
        else:
            features = np.array([self.n_dof, 15.0, 5.0, 0.0])  # é»˜è®¤å€¼
        
        return features.astype(np.float32)
    
    def reset(self, seed=None, options=None):
        """é‡ç½®ç¯å¢ƒï¼ˆgymnasiumå…¼å®¹ï¼‰"""
        # è®¾ç½®éšæœºç§å­
        if seed is not None:
            np.random.seed(seed)
        
        # é‡ç½®å…³èŠ‚åˆ°åˆå§‹ä½ç½®
        for j in self.controllable_joints:
            p.resetJointState(self.robot_id, j, 0.0)
        
        self.current_step = 0
        
        obs = self._get_obs()
        info = {}
        
        return obs, info
    
    def _get_obs(self):
        """è·å–è§‚æµ‹"""
        # è·å–å½“å‰çŠ¶æ€
        joint_states = p.getJointStates(self.robot_id, self.controllable_joints)
        q = np.array([s[0] for s in joint_states])
        qd = np.array([s[1] for s in joint_states])
        
        # å‚è€ƒè½¨è¿¹
        q_ref = self._get_reference_trajectory()
        
        # è¯¯å·®
        error = q_ref - q
        
        # æ—¶é—´å½’ä¸€åŒ–
        time_normalized = self.current_step / self.max_steps
        
        obs = np.concatenate([q, qd, error, [time_normalized]])
        
        return obs.astype(np.float32)
    
    def _get_reference_trajectory(self):
        """ç”Ÿæˆå‚è€ƒè½¨è¿¹ï¼ˆæ­£å¼¦æ³¢ï¼‰"""
        t = self.current_step * 1./240.
        q_ref = np.array([
            0.3 * np.sin(2 * np.pi * 0.5 * t + i * 0.5) 
            for i in range(self.n_dof)
        ])
        return q_ref
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        # RLè¾“å‡ºï¼šè°ƒæ•´æ¯”ä¾‹
        delta_kp_ratio, delta_kd_ratio = action
        
        # å®é™…PID = åŸºå‡†PID Ã— (1 + è°ƒæ•´æ¯”ä¾‹)
        current_kp = self.base_pid[0] * (1 + delta_kp_ratio)
        current_kd = self.base_pid[2] * (1 + delta_kd_ratio)
        
        # ä½¿ç”¨POSITION_CONTROLåº”ç”¨PID
        q_ref = self._get_reference_trajectory()
        
        p.setJointMotorControlArray(
            self.robot_id,
            self.controllable_joints,
            p.POSITION_CONTROL,
            targetPositions=q_ref,
            positionGains=[current_kp] * self.n_dof,
            velocityGains=[current_kd] * self.n_dof,
            forces=[100.0] * self.n_dof
        )
        
        p.stepSimulation()
        
        # è·å–æ–°çŠ¶æ€
        obs = self._get_obs()
        
        # è®¡ç®—å¥–åŠ±
        joint_states = p.getJointStates(self.robot_id, self.controllable_joints)
        q = np.array([s[0] for s in joint_states])
        qd = np.array([s[1] for s in joint_states])
        error = q_ref - q
        
        # å¥–åŠ±è®¾è®¡ï¼ˆå½’ä¸€åŒ–ï¼Œé¿å…æ•°å€¼çˆ†ç‚¸ï¼‰
        # 1. å½’ä¸€åŒ–è·Ÿè¸ªè¯¯å·®ï¼ˆé™¤ä»¥sqrt(n_dof)ä½¿å…¶ä¸å…³èŠ‚æ•°æ— å…³ï¼‰
        tracking_error_norm = np.linalg.norm(error) / np.sqrt(self.n_dof)
        
        # 2. å½’ä¸€åŒ–é€Ÿåº¦å’ŒåŠ¨ä½œ
        velocity_norm = np.linalg.norm(qd) / np.sqrt(self.n_dof)
        action_norm = np.linalg.norm(action)
        
        # 3. è®¡ç®—å¥–åŠ±ï¼ˆæƒé‡æ›´åˆç†ï¼‰
        reward = (
            -10.0 * tracking_error_norm   # ä¸»è¦ï¼šè·Ÿè¸ªè¯¯å·®ï¼ˆå½’ä¸€åŒ–åï¼‰
            -0.1 * velocity_norm          # æ¬¡è¦ï¼šé€Ÿåº¦å¹³æ»‘
            -0.1 * action_norm            # æ¬¡è¦ï¼šåŠ¨ä½œå¹³æ»‘
        )
        
        # 4. å¥–åŠ±è£å‰ªï¼ˆé¿å…æç«¯æƒ…å†µï¼‰
        reward = np.clip(reward, -100.0, 10.0)
        
        self.current_step += 1
        
        # gymnasiumæ ¼å¼ï¼šseparated terminated and truncated
        terminated = False  # æ²¡æœ‰æ˜ç¡®çš„ç»ˆæ­¢æ¡ä»¶
        truncated = (self.current_step >= self.max_steps)  # æ—¶é—´æ­¥æ•°è¾¾åˆ°ä¸Šé™
        
        info = {
            'tracking_error': tracking_error_norm,  # å½’ä¸€åŒ–åçš„è¯¯å·®
            'current_kp': current_kp,
            'current_kd': current_kd,
        }
        
        return obs, reward, terminated, truncated, info
    
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        p.disconnect(self.client)


# ============================================================================
# æµ‹è¯•
# ============================================================================
if __name__ == '__main__':
    print("=" * 80)
    print("æµ‹è¯• Meta-PID + RL ç»„åˆç¯å¢ƒ")
    print("=" * 80)
    
    # åˆ›å»ºç¯å¢ƒ
    env = MetaRLCombinedEnv(
        robot_urdf='franka_panda/panda.urdf',
        gui=False,
        adjustment_range=0.2  # Â±20%è°ƒæ•´èŒƒå›´
    )
    
    print(f"\nâœ… ç¯å¢ƒåˆ›å»ºæˆåŠŸ")
    print(f"   è§‚æµ‹ç©ºé—´: {env.observation_space.shape}")
    print(f"   åŠ¨ä½œç©ºé—´: {env.action_space.shape}")
    
    # æµ‹è¯•reset
    obs = env.reset()
    print(f"\nğŸ“Š åˆå§‹è§‚æµ‹å½¢çŠ¶: {obs.shape}")
    
    # æµ‹è¯•stepï¼ˆéšæœºåŠ¨ä½œï¼‰
    print(f"\nğŸ® æµ‹è¯•10æ­¥...")
    for i in range(10):
        action = env.action_space.sample()  # éšæœºè°ƒæ•´
        obs, reward, done, info = env.step(action)
        
        if i % 5 == 0:
            print(f"   Step {i}: reward={reward:.2f}, "
                  f"error={info['tracking_error']:.4f}, "
                  f"Kp={info['current_kp']:.2f}")
    
    env.close()
    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
    
    print(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    print(f"   python train_meta_rl_combined.py")

